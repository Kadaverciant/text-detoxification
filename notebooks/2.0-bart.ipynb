{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Bart-paraphrase"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T19:44:26.394741Z","iopub.status.busy":"2023-11-03T19:44:26.393901Z","iopub.status.idle":"2023-11-03T19:44:26.400489Z","shell.execute_reply":"2023-11-03T19:44:26.399329Z","shell.execute_reply.started":"2023-11-03T19:44:26.394701Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\kadav\\VSCodeProjects\\PMLDL\\Assignment\\text-detoxification\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import pandas as pd\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    DataCollatorForSeq2Seq,\n","    Seq2SeqTrainer,\n","    Seq2SeqTrainingArguments,\n",")\n","from datasets import Dataset\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["## Load data"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T19:44:26.631126Z","iopub.status.busy":"2023-11-03T19:44:26.630796Z","iopub.status.idle":"2023-11-03T19:44:27.497934Z","shell.execute_reply":"2023-11-03T19:44:27.497048Z","shell.execute_reply.started":"2023-11-03T19:44:26.631098Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>toxic</th>\n","      <th>non-toxic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>I'm not gonna have a child... ...with the same...</td>\n","      <td>I'm not going to breed kids with a genetic dis...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>They're all laughing at us, so we'll kick your...</td>\n","      <td>they're laughing at us. We'll show you.</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Come on, Cal, leave that shit alone.</td>\n","      <td>come on, Cal, put it down.</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Real life starts the first time you fuck, kid.</td>\n","      <td>boy, real life starts up first.</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Shit, this one I can't even pronounce.</td>\n","      <td>gosh, I can't even pronounce this.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                toxic  \\\n","5   I'm not gonna have a child... ...with the same...   \n","6   They're all laughing at us, so we'll kick your...   \n","13               Come on, Cal, leave that shit alone.   \n","22     Real life starts the first time you fuck, kid.   \n","25             Shit, this one I can't even pronounce.   \n","\n","                                            non-toxic  \n","5   I'm not going to breed kids with a genetic dis...  \n","6             they're laughing at us. We'll show you.  \n","13                         come on, Cal, put it down.  \n","22                    boy, real life starts up first.  \n","25                 gosh, I can't even pronounce this.  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"../data/raw/suitable.csv\", index_col=0)\n","df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T19:44:27.500280Z","iopub.status.busy":"2023-11-03T19:44:27.499975Z","iopub.status.idle":"2023-11-03T19:44:27.573838Z","shell.execute_reply":"2023-11-03T19:44:27.572899Z","shell.execute_reply.started":"2023-11-03T19:44:27.500253Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["10000 1000\n"]}],"source":["seed = 177013\n","train = df.sample(10000, random_state=seed)\n","val = df.drop(train.index).sample(1000, random_state=seed)\n","print(len(train), len(val))"]},{"cell_type":"markdown","metadata":{},"source":["## Model training"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T19:44:27.576019Z","iopub.status.busy":"2023-11-03T19:44:27.575218Z","iopub.status.idle":"2023-11-03T19:44:34.015626Z","shell.execute_reply":"2023-11-03T19:44:34.014787Z","shell.execute_reply.started":"2023-11-03T19:44:27.575948Z"},"trusted":true},"outputs":[],"source":["model_name = \"eugenesiow/bart-paraphrase\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T20:15:16.122795Z","iopub.status.busy":"2023-11-03T20:15:16.122398Z","iopub.status.idle":"2023-11-03T20:15:17.092971Z","shell.execute_reply":"2023-11-03T20:15:17.092049Z","shell.execute_reply.started":"2023-11-03T20:15:16.122763Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f777ef35cc84ca5af1d9912db148c07","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e6c3198a71a4e70bd5dcbc397a9bd85","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def tokenize_function(data):\n","    inputs = [\"paraphrase to be nontoxic: \\n\" + text for text in data[\"toxic\"]]\n","    targets = data[\"non-toxic\"]\n","    return tokenizer(inputs, text_target=targets, max_length=64, truncation=True)\n","\n","train_dataset = Dataset.from_pandas(train).map(tokenize_function, batched=True)\n","val_dataset = Dataset.from_pandas(val).map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T20:15:25.769869Z","iopub.status.busy":"2023-11-03T20:15:25.769192Z","iopub.status.idle":"2023-11-03T20:49:17.154524Z","shell.execute_reply":"2023-11-03T20:49:17.153631Z","shell.execute_reply.started":"2023-11-03T20:15:25.769835Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3130' max='3130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3130/3130 33:50, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.955216</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.348700</td>\n","      <td>3.058694</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.348700</td>\n","      <td>3.259816</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.242000</td>\n","      <td>3.297467</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.160400</td>\n","      <td>3.559584</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.160400</td>\n","      <td>3.425686</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.106700</td>\n","      <td>3.573632</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.070000</td>\n","      <td>3.589448</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.070000</td>\n","      <td>3.651816</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.046300</td>\n","      <td>3.711815</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=3130, training_loss=0.157196182031601, metrics={'train_runtime': 2030.6712, 'train_samples_per_second': 49.245, 'train_steps_per_second': 1.541, 'total_flos': 1.01777729028096e+16, 'train_loss': 0.157196182031601, 'epoch': 10.0})"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"../models/bart\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=1e-4,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    weight_decay=0.01,\n","    save_strategy=\"no\",\n","    num_train_epochs=10,\n","    report_to=\"none\",\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T20:50:36.977615Z","iopub.status.busy":"2023-11-03T20:50:36.977140Z","iopub.status.idle":"2023-11-03T20:50:39.402961Z","shell.execute_reply":"2023-11-03T20:50:39.402120Z","shell.execute_reply.started":"2023-11-03T20:50:36.977580Z"},"trusted":true},"outputs":[],"source":["trainer.save_model(\"../models/bart\")"]},{"cell_type":"markdown","metadata":{},"source":["## Check model"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T20:52:13.282968Z","iopub.status.busy":"2023-11-03T20:52:13.281861Z","iopub.status.idle":"2023-11-03T20:52:18.907143Z","shell.execute_reply":"2023-11-03T20:52:18.906251Z","shell.execute_reply.started":"2023-11-03T20:52:13.282919Z"},"trusted":true},"outputs":[],"source":["my_model = AutoModelForSeq2SeqLM.from_pretrained(\"../models/bart\")\n","my_tokenizer = AutoTokenizer.from_pretrained(\"../models/bart\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T20:52:56.931354Z","iopub.status.busy":"2023-11-03T20:52:56.930598Z","iopub.status.idle":"2023-11-03T20:52:56.937821Z","shell.execute_reply":"2023-11-03T20:52:56.936724Z","shell.execute_reply.started":"2023-11-03T20:52:56.931321Z"},"trusted":true},"outputs":[],"source":["my_model.eval()\n","my_model.config.use_cache = False"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T20:54:32.770153Z","iopub.status.busy":"2023-11-03T20:54:32.769779Z","iopub.status.idle":"2023-11-03T20:54:34.293668Z","shell.execute_reply":"2023-11-03T20:54:34.292713Z","shell.execute_reply.started":"2023-11-03T20:54:32.770121Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'I said to you, go to the mid.'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["def generate(model, tokenizer, prompt):\n","    prompt = \"paraphrase to be nontoxic: \\n\" + prompt\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n","    outputs = model.generate(input_ids=input_ids)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","\n","generate(my_model, my_tokenizer, \"You stupid bastards, I said to you, go to the fucking mid. Retard!\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1000\n"]}],"source":["test = df.drop(train.index).drop(val.index).sample(1000, random_state=seed)\n","print(len(test))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>toxic</th>\n","      <th>non-toxic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>399522</th>\n","      <td>I'll show you who's got bigger butts on this s...</td>\n","      <td>I'll show you who's got The bigger bottom roun...</td>\n","    </tr>\n","    <tr>\n","      <th>32832</th>\n","      <td>\"I sit on the floor and pick my nose and think...</td>\n","      <td>\"I sit down and I pick my nose, and on my nose...</td>\n","    </tr>\n","    <tr>\n","      <th>126205</th>\n","      <td>did you know I really thought this grease monk...</td>\n","      <td>You know, I thought that greaser really did tu...</td>\n","    </tr>\n","    <tr>\n","      <th>151854</th>\n","      <td>Just go, tyler, get the hell away from me.</td>\n","      <td>go, Tyler, get away from me.</td>\n","    </tr>\n","    <tr>\n","      <th>218096</th>\n","      <td>'You're putrid, you know that?' Danny said.</td>\n","      <td>\"you're cute, you know?\" Said Danny.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    toxic  \\\n","399522  I'll show you who's got bigger butts on this s...   \n","32832   \"I sit on the floor and pick my nose and think...   \n","126205  did you know I really thought this grease monk...   \n","151854         Just go, tyler, get the hell away from me.   \n","218096        'You're putrid, you know that?' Danny said.   \n","\n","                                                non-toxic  \n","399522  I'll show you who's got The bigger bottom roun...  \n","32832   \"I sit down and I pick my nose, and on my nose...  \n","126205  You know, I thought that greaser really did tu...  \n","151854                       go, Tyler, get away from me.  \n","218096               \"you're cute, you know?\" Said Danny.  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["test.head()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>toxic</th>\n","      <th>non-toxic</th>\n","      <th>generated</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>399522</th>\n","      <td>I'll show you who's got bigger butts on this s...</td>\n","      <td>I'll show you who's got The bigger bottom roun...</td>\n","      <td>I'll show you who's got more cigarettes on thi...</td>\n","    </tr>\n","    <tr>\n","      <th>32832</th>\n","      <td>\"I sit on the floor and pick my nose and think...</td>\n","      <td>\"I sit down and I pick my nose, and on my nose...</td>\n","      <td>\"I sit on the floor and pick at people's shoes...</td>\n","    </tr>\n","    <tr>\n","      <th>126205</th>\n","      <td>did you know I really thought this grease monk...</td>\n","      <td>You know, I thought that greaser really did tu...</td>\n","      <td>Did you know I really thought that this crooke...</td>\n","    </tr>\n","    <tr>\n","      <th>151854</th>\n","      <td>Just go, tyler, get the hell away from me.</td>\n","      <td>go, Tyler, get away from me.</td>\n","      <td>go, tyler, get away from me.</td>\n","    </tr>\n","    <tr>\n","      <th>218096</th>\n","      <td>'You're putrid, you know that?' Danny said.</td>\n","      <td>\"you're cute, you know?\" Said Danny.</td>\n","      <td>\"you're in trouble, you know that?\" Danny said.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    toxic  \\\n","399522  I'll show you who's got bigger butts on this s...   \n","32832   \"I sit on the floor and pick my nose and think...   \n","126205  did you know I really thought this grease monk...   \n","151854         Just go, tyler, get the hell away from me.   \n","218096        'You're putrid, you know that?' Danny said.   \n","\n","                                                non-toxic  \\\n","399522  I'll show you who's got The bigger bottom roun...   \n","32832   \"I sit down and I pick my nose, and on my nose...   \n","126205  You know, I thought that greaser really did tu...   \n","151854                       go, Tyler, get away from me.   \n","218096               \"you're cute, you know?\" Said Danny.   \n","\n","                                                generated  \n","399522  I'll show you who's got more cigarettes on thi...  \n","32832   \"I sit on the floor and pick at people's shoes...  \n","126205  Did you know I really thought that this crooke...  \n","151854                       go, tyler, get away from me.  \n","218096    \"you're in trouble, you know that?\" Danny said.  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["test['generated'] = test['toxic'].map(lambda prompt: generate(my_model, my_tokenizer, prompt))\n","test.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Save results"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["test.to_csv(\"../data/interim/bart_pred.csv\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
